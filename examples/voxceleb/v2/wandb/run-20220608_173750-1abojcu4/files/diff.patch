diff --git a/examples/voxceleb/v2/conf/resnet.yaml b/examples/voxceleb/v2/conf/resnet.yaml
index 9387500..89da6fc 100644
--- a/examples/voxceleb/v2/conf/resnet.yaml
+++ b/examples/voxceleb/v2/conf/resnet.yaml
@@ -37,7 +37,7 @@ dataset_args:
     prob: 0.6
 
 model: ResNet34 # ResNet18, ResNet34, ResNet50, ResNet101, ResNet152
-model_init: null
+model_init: exp/ResNet101-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150/models/model_45.pt
 model_args:
   feat_dim: 80
   embed_dim: 256
diff --git a/examples/voxceleb/v2/local/download_data.sh b/examples/voxceleb/v2/local/download_data.sh
index 89d56de..ff068d9 100755
--- a/examples/voxceleb/v2/local/download_data.sh
+++ b/examples/voxceleb/v2/local/download_data.sh
@@ -22,33 +22,4 @@ if [ ! -f ${download_dir}/rirs_noises.zip ]; then
   [ $md5 != "e6f48e257286e05de56413b4779d8ffb" ] && echo "Wrong md5sum of rirs_noises.zip" && exit 1
 fi
 
-if [ ! -f ${download_dir}/vox1_test_wav.zip ]; then
-  echo "Downloading vox1_test_wav.zip ..."
-  wget --no-check-certificate https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip -P ${download_dir}
-  md5=$(md5sum ${download_dir}/vox1_test_wav.zip | awk '{print $1}')
-  [ $md5 != "185fdc63c3c739954633d50379a3d102" ] && echo "Wrong md5sum of vox1_test_wav.zip" && exit 1
-fi
-
-if [ ! -f ${download_dir}/vox1_dev_wav.zip ]; then
-  echo "Downloading vox1_dev_wav.zip ..."
-  for part in a b c d; do
-    wget --no-check-certificate https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_parta${part} -P ${download_dir} &
-  done
-  wait
-  cat ${download_dir}/vox1_dev* >${download_dir}/vox1_dev_wav.zip
-  md5=$(md5sum ${download_dir}/vox1_dev_wav.zip | awk '{print $1}')
-  [ $md5 != "ae63e55b951748cc486645f532ba230b" ] && echo "Wrong md5sum of vox1_dev_wav.zip" && exit 1
-fi
-
-if [ ! -f ${download_dir}/vox2_aac.zip ]; then
-  echo "Downloading vox2_aac.zip ..."
-  for part in a b c d e f g h; do
-    wget --no-check-certificate https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_dev_aac_parta${part} -P ${download_dir} &
-  done
-  wait
-  cat ${download_dir}/vox2_dev_aac* >${download_dir}/vox2_aac.zip
-  md5=$(md5sum ${download_dir}/vox2_aac.zip | awk '{print $1}')
-  [ $md5 != "bbc063c46078a602ca71605645c2a402" ] && echo "Wrong md5sum of vox2_aac.zip" && exit 1
-fi
-
 echo "Download success !!!"
diff --git a/examples/voxceleb/v2/local/prepare_data.sh b/examples/voxceleb/v2/local/prepare_data.sh
index b30b0de..f3fbf85 100755
--- a/examples/voxceleb/v2/local/prepare_data.sh
+++ b/examples/voxceleb/v2/local/prepare_data.sh
@@ -21,7 +21,7 @@ if [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then
   echo "Decompress all archives ..."
   echo "This could take some time ..."
 
-  for archive in musan.tar.gz rirs_noises.zip vox1_test_wav.zip vox1_dev_wav.zip vox2_aac.zip; do
+  for archive in musan.tar.gz rirs_noises.zip; do
     [ ! -f ${download_dir}/$archive ] && echo "Archive $archive not exists !!!" && exit 1
   done
   [ ! -d ${rawdata_dir} ] && mkdir -p ${rawdata_dir}
@@ -34,41 +34,9 @@ if [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then
     unzip ${download_dir}/rirs_noises.zip -d ${rawdata_dir}
   fi
 
-  if [ ! -d ${rawdata_dir}/voxceleb1 ]; then
-    mkdir -p ${rawdata_dir}/voxceleb1/test ${rawdata_dir}/voxceleb1/dev
-    unzip ${download_dir}/vox1_test_wav.zip -d ${rawdata_dir}/voxceleb1/test
-    unzip ${download_dir}/vox1_dev_wav.zip -d ${rawdata_dir}/voxceleb1/dev
-  fi
-
-  if [ ! -d ${rawdata_dir}/voxceleb2_m4a ]; then
-    mkdir -p ${rawdata_dir}/voxceleb2_m4a
-    unzip ${download_dir}/vox2_aac.zip -d ${rawdata_dir}/voxceleb2_m4a
-  fi
-
   echo "Decompress success !!!"
 fi
 
-if [ ${stage} -le 3 ] && [ ${stop_stage} -ge 3 ]; then
-  echo "Convert voxceleb2 wav format from m4a to wav using ffmpeg."
-  echo "This could also take some time ..."
-
-  if [ ! -d ${rawdata_dir}/voxceleb2_wav ]; then
-    ./local/m4a2wav.pl ${rawdata_dir}/voxceleb2_m4a dev ${rawdata_dir}/voxceleb2_wav
-    # split m4a2wav_dev.sh into sub_file, then we can use multi progresses
-    data_num=$(wc -l ${rawdata_dir}/voxceleb2_wav/dev/m4a2wav_dev.sh | awk '{print $1}')
-    nj=8 # num of jobs
-    subfile_num=$(($data_num / $nj + 1))
-    split -l ${subfile_num} -d -a 3 ${rawdata_dir}/voxceleb2_wav/dev/m4a2wav_dev.sh ${rawdata_dir}/voxceleb2_wav/dev/split_
-    for suffix in $(seq 0 $(($nj - 1))); do
-      suffix=$(printf '%03d' $suffix)
-      sh ${rawdata_dir}/voxceleb2_wav/dev/split_${suffix} &
-    done
-    wait
-  fi
-
-  echo "Convert m4a2wav success !!!"
-fi
-
 if [ ${stage} -le 4 ] && [ ${stop_stage} -ge 4 ]; then
   echo "Prepare wav.scp for each dataset ..."
   export LC_ALL=C # kaldi config
@@ -78,28 +46,6 @@ if [ ${stage} -le 4 ] && [ ${stop_stage} -ge 4 ]; then
   find $(pwd)/${rawdata_dir}/musan -name "*.wav" | awk -F"/" '{print $(NF-2)"/"$(NF-1)"/"$NF,$0}' >data/musan/wav.scp
   # rirs
   find $(pwd)/${rawdata_dir}/RIRS_NOISES/simulated_rirs -name "*.wav" | awk -F"/" '{print $(NF-2)"/"$(NF-1)"/"$NF,$0}' >data/rirs/wav.scp
-  # vox1
-  find $(pwd)/${rawdata_dir}/voxceleb1 -name "*.wav" | awk -F"/" '{print $(NF-2)"/"$(NF-1)"/"$NF,$0}' | sort >data/vox1/wav.scp
-  awk '{print $1}' data/vox1/wav.scp | awk -F "/" '{print $0,$1}' >data/vox1/utt2spk
-  ./tools/utt2spk_to_spk2utt.pl data/vox1/utt2spk >data/vox1/spk2utt
-  if [ ! -d data/vox1/trials ]; then
-    echo "Download trials for vox1 ..."
-    mkdir -p data/vox1/trials
-    #wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt -O data/vox1/trials/vox1-O.txt
-    #wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_hard.txt -O data/vox1/trials/vox1-H.txt
-    #wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_all.txt -O data/vox1/trials/vox1-E.txt
-    wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test2.txt -O data/vox1/trials/vox1-O\(cleaned\).txt
-    wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_hard2.txt -O data/vox1/trials/vox1-H\(cleaned\).txt
-    wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_all2.txt -O data/vox1/trials/vox1-E\(cleaned\).txt
-    # transform them into kaldi trial format
-    awk '{if($1==0)label="nontarget";else{label="target"}; print $2,$3,label}' data/vox1/trials/vox1-O\(cleaned\).txt >data/vox1/trials/vox1_O_cleaned.kaldi
-    awk '{if($1==0)label="nontarget";else{label="target"}; print $2,$3,label}' data/vox1/trials/vox1-H\(cleaned\).txt >data/vox1/trials/vox1_H_cleaned.kaldi
-    awk '{if($1==0)label="nontarget";else{label="target"}; print $2,$3,label}' data/vox1/trials/vox1-E\(cleaned\).txt >data/vox1/trials/vox1_E_cleaned.kaldi
-  fi
-  # vox2
-  find $(pwd)/${rawdata_dir}/voxceleb2_wav -name "*.wav" | awk -F"/" '{print $(NF-2)"/"$(NF-1)"/"$NF,$0}' | sort >data/vox2_dev/wav.scp
-  awk '{print $1}' data/vox2_dev/wav.scp | awk -F "/" '{print $0,$1}' >data/vox2_dev/utt2spk
-  ./tools/utt2spk_to_spk2utt.pl data/vox2_dev/utt2spk >data/vox2_dev/spk2utt
 
   echo "Success !!!"
 fi
diff --git a/examples/voxceleb/v2/run.sh b/examples/voxceleb/v2/run.sh
index 3b3d060..56d3bd1 100755
--- a/examples/voxceleb/v2/run.sh
+++ b/examples/voxceleb/v2/run.sh
@@ -8,9 +8,9 @@ stage=-1
 stop_stage=-1
 
 config=conf/resnet.yaml
-exp_dir=exp/ResNet34-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150
+exp_dir=exp/ResNet101-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150
 data_type="shard"  # shard/raw
-gpus="[0,1]"
+gpus="[0,1,2,3]"
 num_avg=10
 checkpoint=
 
diff --git a/tools/make_lmdb.py b/tools/make_lmdb.py
index 389f31b..1dc7853 100644
--- a/tools/make_lmdb.py
+++ b/tools/make_lmdb.py
@@ -32,7 +32,7 @@ def get_args():
 
 def main():
     args = get_args()
-    db = lmdb.open(args.out_lmdb, map_size=int(math.pow(1024, 4)))  # 1TB
+    db = lmdb.open(args.out_lmdb, map_size=int(math.pow(512, 4)))  # 1TB
     # txn is for Transaciton
     txn = db.begin(write=True)
     keys = []
diff --git a/wespeaker/bin/train.py b/wespeaker/bin/train.py
index d27dff1..24cb9d1 100644
--- a/wespeaker/bin/train.py
+++ b/wespeaker/bin/train.py
@@ -12,6 +12,7 @@ import re
 import torch
 import torch.distributed as dist
 from torch.utils.data import DataLoader
+import wandb
 
 import wespeaker.utils.schedulers as schedulers
 from wespeaker.models.speaker_model import get_speaker_model
@@ -30,6 +31,7 @@ def train(config='conf/config.yaml', **kwargs):
     :returns: None
     """
     configs = parse_config_or_kwargs(config, **kwargs)
+
     checkpoint = configs.get('checkpoint', None)
     # dist configs
     rank = int(os.environ['LOCAL_RANK'])
@@ -40,6 +42,9 @@ def train(config='conf/config.yaml', **kwargs):
 
     model_dir = os.path.join(configs['exp_dir'], "models")
     if rank == 0:
+        wandb.login(host="http://wandb.speech-rnd.internal",
+                    key="local-473ad2cf1f9ed9023faf837048e75943e1bbe7c5")
+        wandb.init(project='Jan_DIAR-88', config=configs)
         try:
             os.makedirs(model_dir)
         except IOError:
@@ -175,6 +180,9 @@ def train(config='conf/config.yaml', **kwargs):
             logger.info(line)
     dist.barrier()  # synchronize here
 
+    if rank == 0:
+        wandb.watch(ddp_model)
+
     for epoch in range(start_epoch, configs['num_epochs'] + 1):
         # train_sampler.set_epoch(epoch)
         train_dataset.set_epoch(epoch)
@@ -189,7 +197,8 @@ def train(config='conf/config.yaml', **kwargs):
                   epoch,
                   logger,
                   log_batch_interval=configs['log_batch_interval'],
-                  device=device)
+                  device=device,
+                  wandb=wandb)
 
         if rank == 0:
             if epoch % configs['save_epoch_interval'] == 0 or epoch >= configs[
diff --git a/wespeaker/utils/executor.py b/wespeaker/utils/executor.py
index be175be..9837011 100644
--- a/wespeaker/utils/executor.py
+++ b/wespeaker/utils/executor.py
@@ -19,7 +19,8 @@ def run_epoch(dataloader,
               epoch,
               logger,
               log_batch_interval=100,
-              device=torch.device('cuda')):
+              device=torch.device('cuda'),
+              wandb=None):
     model.train()
     # By default use average pooling
     loss_meter = tnt.meter.AverageValueMeter()
@@ -67,9 +68,12 @@ def run_epoch(dataloader,
                            width=10,
                            style='grid'))
 
+
     logger.info(
         tp.row((epoch, i + 1, scheduler.get_lr(),
                 margin_scheduler.get_margin()) +
                (loss_meter.value()[0], acc_meter.value()[0]),
                width=10,
                style='grid'))
+    if wandb is not None:
+        wandb.log({'epoch': epoch, 'lr': scheduler.get_lr(), 'margin': margin_scheduler.get_margin(), 'loss': loss_meter.value()[0], 'acc': acc_meter.value()[0]})
