diff --git a/examples/voxceleb/v2/conf/resnet.yaml b/examples/voxceleb/v2/conf/resnet.yaml
index 9387500..1ca0bf6 100644
--- a/examples/voxceleb/v2/conf/resnet.yaml
+++ b/examples/voxceleb/v2/conf/resnet.yaml
@@ -10,8 +10,8 @@ save_epoch_interval: 5 # save model every 5 epochs
 log_batch_interval: 100 # log every 100 batchs
 
 dataloader_args:
-  batch_size: 128
-  num_workers: 8
+  batch_size: 192
+  num_workers: 4
   pin_memory: False
   prefetch_factor: 4
   drop_last: True
@@ -37,7 +37,7 @@ dataset_args:
     prob: 0.6
 
 model: ResNet34 # ResNet18, ResNet34, ResNet50, ResNet101, ResNet152
-model_init: null
+model_init: exp/ResNet101-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150/models/model_45.pt
 model_args:
   feat_dim: 80
   embed_dim: 256
diff --git a/examples/voxceleb/v2/local/download_data.sh b/examples/voxceleb/v2/local/download_data.sh
index 89d56de..ff068d9 100755
--- a/examples/voxceleb/v2/local/download_data.sh
+++ b/examples/voxceleb/v2/local/download_data.sh
@@ -22,33 +22,4 @@ if [ ! -f ${download_dir}/rirs_noises.zip ]; then
   [ $md5 != "e6f48e257286e05de56413b4779d8ffb" ] && echo "Wrong md5sum of rirs_noises.zip" && exit 1
 fi
 
-if [ ! -f ${download_dir}/vox1_test_wav.zip ]; then
-  echo "Downloading vox1_test_wav.zip ..."
-  wget --no-check-certificate https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_test_wav.zip -P ${download_dir}
-  md5=$(md5sum ${download_dir}/vox1_test_wav.zip | awk '{print $1}')
-  [ $md5 != "185fdc63c3c739954633d50379a3d102" ] && echo "Wrong md5sum of vox1_test_wav.zip" && exit 1
-fi
-
-if [ ! -f ${download_dir}/vox1_dev_wav.zip ]; then
-  echo "Downloading vox1_dev_wav.zip ..."
-  for part in a b c d; do
-    wget --no-check-certificate https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox1_dev_wav_parta${part} -P ${download_dir} &
-  done
-  wait
-  cat ${download_dir}/vox1_dev* >${download_dir}/vox1_dev_wav.zip
-  md5=$(md5sum ${download_dir}/vox1_dev_wav.zip | awk '{print $1}')
-  [ $md5 != "ae63e55b951748cc486645f532ba230b" ] && echo "Wrong md5sum of vox1_dev_wav.zip" && exit 1
-fi
-
-if [ ! -f ${download_dir}/vox2_aac.zip ]; then
-  echo "Downloading vox2_aac.zip ..."
-  for part in a b c d e f g h; do
-    wget --no-check-certificate https://thor.robots.ox.ac.uk/~vgg/data/voxceleb/vox1a/vox2_dev_aac_parta${part} -P ${download_dir} &
-  done
-  wait
-  cat ${download_dir}/vox2_dev_aac* >${download_dir}/vox2_aac.zip
-  md5=$(md5sum ${download_dir}/vox2_aac.zip | awk '{print $1}')
-  [ $md5 != "bbc063c46078a602ca71605645c2a402" ] && echo "Wrong md5sum of vox2_aac.zip" && exit 1
-fi
-
 echo "Download success !!!"
diff --git a/examples/voxceleb/v2/local/extract_vox.sh b/examples/voxceleb/v2/local/extract_vox.sh
index c80a53b..18a2f4a 100755
--- a/examples/voxceleb/v2/local/extract_vox.sh
+++ b/examples/voxceleb/v2/local/extract_vox.sh
@@ -4,19 +4,19 @@
 
 exp_dir=''
 model_path=''
-nj=4
-gpus="[0,1]"
+nj=1
+gpus="[0]"
 data_type="shard/raw"  # shard/raw
 
 . tools/parse_options.sh
 set -e
 
-data_name_array=("vox2_dev" "vox1")
-data_list_path_array=("data/vox2_dev/${data_type}.list" "data/vox1/${data_type}.list")
-data_scp_path_array=("data/vox2_dev/wav.scp" "data/vox1/wav.scp") # to count the number of wavs
+data_name_array=("voxceleb1")
+data_list_path_array=("data/voxceleb1/${data_type}.list")
+data_scp_path_array=("data/voxceleb1/wav.scp") # to count the number of wavs
 nj_array=($nj $nj)
-batch_size_array=(16 1) # batch_size of test set must be 1 !!!
-num_workers_array=(4 1)
+batch_size_array=(16) # batch_size of test set must be 1 !!!
+num_workers_array=(4)
 count=${#data_name_array[@]}
 
 for i in $(seq 0 $(($count - 1))); do
@@ -30,7 +30,7 @@ for i in $(seq 0 $(($count - 1))); do
     --batch_size ${batch_size_array[$i]} \
     --num_workers ${num_workers_array[$i]} \
     --nj ${nj_array[$i]} \
-    --gpus $gpus &
+    --gpus $gpus
 done
 
 wait
diff --git a/examples/voxceleb/v2/local/prepare_data.sh b/examples/voxceleb/v2/local/prepare_data.sh
index b30b0de..f3fbf85 100755
--- a/examples/voxceleb/v2/local/prepare_data.sh
+++ b/examples/voxceleb/v2/local/prepare_data.sh
@@ -21,7 +21,7 @@ if [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then
   echo "Decompress all archives ..."
   echo "This could take some time ..."
 
-  for archive in musan.tar.gz rirs_noises.zip vox1_test_wav.zip vox1_dev_wav.zip vox2_aac.zip; do
+  for archive in musan.tar.gz rirs_noises.zip; do
     [ ! -f ${download_dir}/$archive ] && echo "Archive $archive not exists !!!" && exit 1
   done
   [ ! -d ${rawdata_dir} ] && mkdir -p ${rawdata_dir}
@@ -34,41 +34,9 @@ if [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then
     unzip ${download_dir}/rirs_noises.zip -d ${rawdata_dir}
   fi
 
-  if [ ! -d ${rawdata_dir}/voxceleb1 ]; then
-    mkdir -p ${rawdata_dir}/voxceleb1/test ${rawdata_dir}/voxceleb1/dev
-    unzip ${download_dir}/vox1_test_wav.zip -d ${rawdata_dir}/voxceleb1/test
-    unzip ${download_dir}/vox1_dev_wav.zip -d ${rawdata_dir}/voxceleb1/dev
-  fi
-
-  if [ ! -d ${rawdata_dir}/voxceleb2_m4a ]; then
-    mkdir -p ${rawdata_dir}/voxceleb2_m4a
-    unzip ${download_dir}/vox2_aac.zip -d ${rawdata_dir}/voxceleb2_m4a
-  fi
-
   echo "Decompress success !!!"
 fi
 
-if [ ${stage} -le 3 ] && [ ${stop_stage} -ge 3 ]; then
-  echo "Convert voxceleb2 wav format from m4a to wav using ffmpeg."
-  echo "This could also take some time ..."
-
-  if [ ! -d ${rawdata_dir}/voxceleb2_wav ]; then
-    ./local/m4a2wav.pl ${rawdata_dir}/voxceleb2_m4a dev ${rawdata_dir}/voxceleb2_wav
-    # split m4a2wav_dev.sh into sub_file, then we can use multi progresses
-    data_num=$(wc -l ${rawdata_dir}/voxceleb2_wav/dev/m4a2wav_dev.sh | awk '{print $1}')
-    nj=8 # num of jobs
-    subfile_num=$(($data_num / $nj + 1))
-    split -l ${subfile_num} -d -a 3 ${rawdata_dir}/voxceleb2_wav/dev/m4a2wav_dev.sh ${rawdata_dir}/voxceleb2_wav/dev/split_
-    for suffix in $(seq 0 $(($nj - 1))); do
-      suffix=$(printf '%03d' $suffix)
-      sh ${rawdata_dir}/voxceleb2_wav/dev/split_${suffix} &
-    done
-    wait
-  fi
-
-  echo "Convert m4a2wav success !!!"
-fi
-
 if [ ${stage} -le 4 ] && [ ${stop_stage} -ge 4 ]; then
   echo "Prepare wav.scp for each dataset ..."
   export LC_ALL=C # kaldi config
@@ -78,28 +46,6 @@ if [ ${stage} -le 4 ] && [ ${stop_stage} -ge 4 ]; then
   find $(pwd)/${rawdata_dir}/musan -name "*.wav" | awk -F"/" '{print $(NF-2)"/"$(NF-1)"/"$NF,$0}' >data/musan/wav.scp
   # rirs
   find $(pwd)/${rawdata_dir}/RIRS_NOISES/simulated_rirs -name "*.wav" | awk -F"/" '{print $(NF-2)"/"$(NF-1)"/"$NF,$0}' >data/rirs/wav.scp
-  # vox1
-  find $(pwd)/${rawdata_dir}/voxceleb1 -name "*.wav" | awk -F"/" '{print $(NF-2)"/"$(NF-1)"/"$NF,$0}' | sort >data/vox1/wav.scp
-  awk '{print $1}' data/vox1/wav.scp | awk -F "/" '{print $0,$1}' >data/vox1/utt2spk
-  ./tools/utt2spk_to_spk2utt.pl data/vox1/utt2spk >data/vox1/spk2utt
-  if [ ! -d data/vox1/trials ]; then
-    echo "Download trials for vox1 ..."
-    mkdir -p data/vox1/trials
-    #wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt -O data/vox1/trials/vox1-O.txt
-    #wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_hard.txt -O data/vox1/trials/vox1-H.txt
-    #wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_all.txt -O data/vox1/trials/vox1-E.txt
-    wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test2.txt -O data/vox1/trials/vox1-O\(cleaned\).txt
-    wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_hard2.txt -O data/vox1/trials/vox1-H\(cleaned\).txt
-    wget --no-check-certificate https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/list_test_all2.txt -O data/vox1/trials/vox1-E\(cleaned\).txt
-    # transform them into kaldi trial format
-    awk '{if($1==0)label="nontarget";else{label="target"}; print $2,$3,label}' data/vox1/trials/vox1-O\(cleaned\).txt >data/vox1/trials/vox1_O_cleaned.kaldi
-    awk '{if($1==0)label="nontarget";else{label="target"}; print $2,$3,label}' data/vox1/trials/vox1-H\(cleaned\).txt >data/vox1/trials/vox1_H_cleaned.kaldi
-    awk '{if($1==0)label="nontarget";else{label="target"}; print $2,$3,label}' data/vox1/trials/vox1-E\(cleaned\).txt >data/vox1/trials/vox1_E_cleaned.kaldi
-  fi
-  # vox2
-  find $(pwd)/${rawdata_dir}/voxceleb2_wav -name "*.wav" | awk -F"/" '{print $(NF-2)"/"$(NF-1)"/"$NF,$0}' | sort >data/vox2_dev/wav.scp
-  awk '{print $1}' data/vox2_dev/wav.scp | awk -F "/" '{print $0,$1}' >data/vox2_dev/utt2spk
-  ./tools/utt2spk_to_spk2utt.pl data/vox2_dev/utt2spk >data/vox2_dev/spk2utt
 
   echo "Success !!!"
 fi
diff --git a/examples/voxceleb/v2/run.sh b/examples/voxceleb/v2/run.sh
index 3b3d060..56d3bd1 100755
--- a/examples/voxceleb/v2/run.sh
+++ b/examples/voxceleb/v2/run.sh
@@ -8,9 +8,9 @@ stage=-1
 stop_stage=-1
 
 config=conf/resnet.yaml
-exp_dir=exp/ResNet34-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150
+exp_dir=exp/ResNet101-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150
 data_type="shard"  # shard/raw
-gpus="[0,1]"
+gpus="[0,1,2,3]"
 num_avg=10
 checkpoint=
 
diff --git a/examples/voxceleb/v2/run_rev.sh b/examples/voxceleb/v2/run_rev.sh
new file mode 100755
index 0000000..8bfdb5f
--- /dev/null
+++ b/examples/voxceleb/v2/run_rev.sh
@@ -0,0 +1,105 @@
+#!/bin/bash
+# coding:utf-8
+# Author: Hongji Wang
+
+. ./path.sh
+
+stage=-1
+stop_stage=-1
+
+config=conf/resnet.yaml
+exp_dir=exp/ResNet34-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150_rev-data
+data_type="shard"  # shard/raw
+gpus="[0,1,2,3]"
+num_avg=10
+checkpoint=exp/ResNet34-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150/models/avg_model.pt
+#checkpoint=exp/ResNet101-TSTP-emb256-fbank80-num_frms200-aug0.6-spTrue-saFalse-ArcMargin-SGD-epoch150/models/model_45.pt
+
+score_norm_method="asnorm"  # asnorm/snorm
+top_n=100
+trials="vox1_O_cleaned.kaldi vox1_E_cleaned.kaldi vox1_H_cleaned.kaldi"
+
+. tools/parse_options.sh || exit 1
+
+if [ ${stage} -le 1 ] && [ ${stop_stage} -ge 1 ]; then
+  echo "Prepare datasets ..."
+  ./local/prepare_data.sh --stage 1 --stop_stage 4
+fi
+
+if [ ${stage} -le 2 ] && [ ${stop_stage} -ge 2 ]; then
+  echo "Covert train and test data to ${data_type}..."
+  for dset in train; do
+    if [ $data_type == "shard" ]; then
+      python tools/make_shard_list_segments.py --num_utts_per_shard 1000 \
+          --num_threads 8 \
+          --prefix shards \
+          --shuffle \
+          data/$dset/wav.scp data/$dset/utt2spk data/$dset/segments \
+          data/$dset/audio data/$dset/shards data/$dset/shard.list
+    else
+      python tools/make_raw_list.py data/$dset/wav.scp \
+          data/$dset/utt2spk data/$dset/raw.list
+    fi
+  done
+  # Convert all musan data to LMDB
+  # FIXME python tools/make_lmdb.py data/musan/wav.scp data/musan/lmdb
+  # Convert all rirs data to LMDB
+  # FIXME python tools/make_lmdb.py data/rirs/wav.scp data/rirs/lmdb
+fi
+
+if [ ${stage} -le 3 ] && [ ${stop_stage} -ge 3 ]; then
+  echo "Start training ..."
+  num_gpus=$(echo $gpus | awk -F ',' '{print NF}')
+  torchrun --standalone --nnodes=1 --nproc_per_node=$num_gpus \
+    wespeaker/bin/train.py --config $config \
+      --exp_dir ${exp_dir} \
+      --gpus $gpus \
+      --num_avg ${num_avg} \
+      --data_type "${data_type}" \
+      --train_data data/train/${data_type}.list \
+      --train_label data/train/utt2spk \
+      --reverb_data data/rirs/lmdb \
+      --noise_data data/musan/lmdb \
+      ${checkpoint:+--checkpoint $checkpoint}
+fi
+
+if [ ${stage} -le 4 ] && [ ${stop_stage} -ge 4 ]; then
+  echo "Do model average ..."
+  avg_model=$exp_dir/models/avg_model.pt
+  #python wespeaker/bin/average_model.py \
+  #  --dst_model $avg_model \
+  #  --src_path $exp_dir/models \
+  #  --num ${num_avg}
+
+  echo "Extract embeddings ..."
+  local/extract_vox.sh \
+    --exp_dir $exp_dir --model_path $avg_model \
+    --nj 1 --gpus [0] --data_type $data_type
+fi
+
+if [ ${stage} -le 5 ] && [ ${stop_stage} -ge 5 ]; then
+  echo "Score ..."
+  local/score.sh \
+    --stage 1 --stop-stage 2 \
+    --exp_dir $exp_dir \
+    --trials "$trials"
+fi
+
+if [ ${stage} -le 6 ] && [ ${stop_stage} -ge 6 ]; then
+  echo "Score norm ..."
+  local/score_norm.sh \
+    --stage 1 --stop-stage 3 \
+    --score_norm_method $score_norm_method \
+    --cohort_set vox2_dev \
+    --top_n $top_n \
+    --exp_dir $exp_dir \
+    --trials "$trials"
+fi
+
+if [ ${stage} -le 7 ] && [ ${stop_stage} -ge 7 ]; then
+  echo "Export the best model ..."
+  python wespeaker/bin/export_jit.py \
+    --config $exp_dir/config.yaml \
+    --checkpoint $exp_dir/models/avg_model.pt \
+    --output_file $exp_dir/models/final.zip
+fi
diff --git a/tools/make_lmdb.py b/tools/make_lmdb.py
index 389f31b..1dc7853 100644
--- a/tools/make_lmdb.py
+++ b/tools/make_lmdb.py
@@ -32,7 +32,7 @@ def get_args():
 
 def main():
     args = get_args()
-    db = lmdb.open(args.out_lmdb, map_size=int(math.pow(1024, 4)))  # 1TB
+    db = lmdb.open(args.out_lmdb, map_size=int(math.pow(512, 4)))  # 1TB
     # txn is for Transaciton
     txn = db.begin(write=True)
     keys = []
diff --git a/wespeaker/bin/train.py b/wespeaker/bin/train.py
index d27dff1..34d43ee 100644
--- a/wespeaker/bin/train.py
+++ b/wespeaker/bin/train.py
@@ -12,6 +12,7 @@ import re
 import torch
 import torch.distributed as dist
 from torch.utils.data import DataLoader
+import wandb
 
 import wespeaker.utils.schedulers as schedulers
 from wespeaker.models.speaker_model import get_speaker_model
@@ -30,6 +31,7 @@ def train(config='conf/config.yaml', **kwargs):
     :returns: None
     """
     configs = parse_config_or_kwargs(config, **kwargs)
+
     checkpoint = configs.get('checkpoint', None)
     # dist configs
     rank = int(os.environ['LOCAL_RANK'])
@@ -40,6 +42,9 @@ def train(config='conf/config.yaml', **kwargs):
 
     model_dir = os.path.join(configs['exp_dir'], "models")
     if rank == 0:
+        wandb.login(host="http://wandb.speech-rnd.internal",
+                    key="local-473ad2cf1f9ed9023faf837048e75943e1bbe7c5")
+        wandb.init(project='Jan_DIAR-88', config=configs)
         try:
             os.makedirs(model_dir)
         except IOError:
@@ -175,11 +180,14 @@ def train(config='conf/config.yaml', **kwargs):
             logger.info(line)
     dist.barrier()  # synchronize here
 
+    if rank == 0:
+        wandb.watch(ddp_model)
+
     for epoch in range(start_epoch, configs['num_epochs'] + 1):
         # train_sampler.set_epoch(epoch)
         train_dataset.set_epoch(epoch)
 
-        run_epoch(train_dataloader,
+        lr, margin, loss, acc = run_epoch(train_dataloader,
                   loader_size,
                   ddp_model,
                   criterion,
@@ -197,6 +205,7 @@ def train(config='conf/config.yaml', **kwargs):
                 save_checkpoint(
                     model,
                     os.path.join(model_dir, 'model_{}.pt'.format(epoch)))
+            wandb.log({'epoch': epoch, 'lr': lr, 'margin': margin, 'loss': loss, 'acc': acc})
 
     if rank == 0:
         os.symlink('model_{}.pt'.format(configs['num_epochs']),
diff --git a/wespeaker/dataset/dataset.py b/wespeaker/dataset/dataset.py
index 4b13ed2..175e815 100644
--- a/wespeaker/dataset/dataset.py
+++ b/wespeaker/dataset/dataset.py
@@ -1,4 +1,6 @@
-# Copyright (c) 2022 Horizon Robtics. (authors: Binbin Zhang)
+# Copyright (c) 2021 Mobvoi Inc. (authors: Binbin Zhang)
+#               2022 Chengdong Liang (liangchengdong@mail.nwpu.edu.cn)
+#               2022 Hongji Wang (jijijiang77@gmail.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -11,7 +13,7 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
+import os.path
 import random
 
 import torch
@@ -123,23 +125,24 @@ def Dataset(data_type,
             spk2id_dict,
             whole_utt=False,
             reverb_lmdb_file=None,
-            noise_lmdb_file=None):
+            noise_lmdb_file=None,
+            base_path=None):
     """ Construct dataset from arguments
 
         We have two shuffle stage in the Dataset. The first is global
-        shuffle at shards tar/raw file level. The second is local shuffle
+        shuffle at shards tar/raw/feat file level. The second is local shuffle
         at training samples level.
 
         Args:
-            data_type(str): raw/shard
-            data_list_file: shard list file
+            data_type(str): shard/raw/feat
+            data_list_file: data list file
             configs: dataset configs
             spk2id_dict: spk2id dict
             reverb_lmdb_file: reverb data source lmdb file
             noise_lmdb_file: noise data source lmdb file
             whole_utt: use whole utt or random chunk
     """
-    assert data_type in ['raw', 'shard']
+    assert data_type in ['shard', 'raw', 'feat', 'segments']
     lists = read_lists(data_list_file)
     shuffle = configs.get('shuffle', False)
     # Global shuffle
@@ -147,8 +150,12 @@ def Dataset(data_type,
     if data_type == 'shard':
         dataset = Processor(dataset, processor.url_opener)
         dataset = Processor(dataset, processor.tar_file_and_group)
-    else:
+    elif data_type == 'raw':
         dataset = Processor(dataset, processor.parse_raw)
+    elif data_type == 'segments':
+        dataset = Processor((base_path, dataset), processor.parse_segments)
+    else:
+        dataset = Processor(dataset, processor.parse_feat)
     # Local shuffle
     if shuffle:
         dataset = Processor(dataset, processor.shuffle, **configs['shuffle_args'])
@@ -156,25 +163,32 @@ def Dataset(data_type,
     # spk2id
     dataset = Processor(dataset, processor.spk_to_id, spk2id_dict)
 
-    # speed perturb
-    speed_perturb_flag = configs.get('speed_perturb', True)
-    if speed_perturb_flag:
-        dataset = Processor(dataset, processor.speed_perturb, len(spk2id_dict))
-
-    if not whole_utt:
-        # random chunk
-        num_frms = configs.get('num_frms', 200)
-        dataset = Processor(dataset, processor.random_chunk, num_frms)
-
-    # add reverb & noise
-    if reverb_lmdb_file and noise_lmdb_file:
-        reverb_data = LmdbData(reverb_lmdb_file)
-        noise_data = LmdbData(noise_lmdb_file)
-        dataset = Processor(dataset, processor.add_reverb_noise, reverb_data,
-                            noise_data, configs['aug_prob'])
-
-    # compute fbank
-    dataset = Processor(dataset, processor.compute_fbank, **configs['fbank_args'])
+    if data_type == 'feat':
+        if not whole_utt:
+            # random chunk
+            num_frms = configs.get('num_frms', 200)
+            dataset = Processor(dataset, processor.random_chunk, 'feat', num_frms)
+        # apply cmvn
+        dataset = Processor(dataset, processor.apply_cmvn)
+    else:
+        # speed perturb
+        speed_perturb_flag = configs.get('speed_perturb', True)
+        if speed_perturb_flag:
+            dataset = Processor(dataset, processor.speed_perturb, len(spk2id_dict))
+        if not whole_utt:
+            # random chunk
+            num_frms = configs.get('num_frms', 200)
+            dataset = Processor(dataset, processor.random_chunk, data_type, num_frms)
+        # add reverb & noise
+        if reverb_lmdb_file and noise_lmdb_file:
+            reverb_data = LmdbData(reverb_lmdb_file)
+            noise_data = LmdbData(noise_lmdb_file)
+            dataset = Processor(dataset, processor.add_reverb_noise, reverb_data,
+                                noise_data, configs['aug_prob'])
+        # compute fbank
+        dataset = Processor(dataset, processor.compute_fbank, **configs['fbank_args'])
+        # apply cmvn
+        dataset = Processor(dataset, processor.apply_cmvn)
 
     # spec augmentation
     spec_aug_flag = configs.get('spec_aug', True)
diff --git a/wespeaker/dataset/processor.py b/wespeaker/dataset/processor.py
index b3b54f8..5db5364 100644
--- a/wespeaker/dataset/processor.py
+++ b/wespeaker/dataset/processor.py
@@ -1,4 +1,6 @@
-# Copyright (c) 2022 Horizon Robtics. (authors: Binbin Zhang)
+# Copyright (c) 2021 Mobvoi Inc. (authors: Binbin Zhang)
+#               2022 Chengdong Liang (liangchengdong@mail.nwpu.edu.cn)
+#               2022 Hongji Wang (jijijiang77@gmail.com)
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
@@ -13,9 +15,12 @@
 # limitations under the License.
 
 import io
+import kaldiio
 import json
 import logging
+import os
 import random
+import re
 import tarfile
 from subprocess import PIPE, Popen
 from urllib.parse import urlparse
@@ -142,6 +147,85 @@ def parse_raw(data):
             logging.warning('Failed to read {}'.format(wav_file))
 
 
+def parse_segments(data):
+    bdir, data = data
+    with open(os.path.join(bdir, 'wav.scp')) as f:
+        lines = f.readlines()
+        assert len(lines) == 1
+        wav = lines[0].split()[1]
+        assert os.path.isfile(wav), f'Missing wave file {wav}.'
+
+    waveform, sample_rate = None, None
+    for sample_idx, sample in enumerate(data):
+        assert 'src' in sample
+        segment, utt, start_sec, end_sec = sample['src'].split()
+        utt = utt[:-2]
+        start_sec, end_sec = float(start_sec), float(end_sec)
+
+        if waveform is None:
+            waveform, sample_rate = torchaudio.load(wav)
+
+        # print(start_sec, end_sec)
+        waveform_segment = waveform[:, int(start_sec * sample_rate):int(end_sec * sample_rate)]
+        slen = waveform_segment.shape[1]
+        seg_len, seg_jump = int(1.2 * sample_rate), int(0.24 * sample_rate)
+        start = 0
+        # print(f'{bdir} {waveform_segment.shape} {start_sec} {end_sec} {slen} {seg_len} {seg_jump}\n')
+        for start in range(0, slen - seg_len, seg_jump):
+            key = f'{utt}-A_{sample_idx:04}-' \
+                  f'{int(start / sample_rate * 100):08}-{int((start + seg_len) / sample_rate * 100):08}'
+            assert start <= start + seg_len <= waveform_segment.shape[1], \
+                f'Start: {start}, end: {start + seg_len}, shape: {waveform_segment.shape[1]}'
+            example = dict(key=key,
+                           spk=(start / sample_rate + start_sec, (start + seg_len) / sample_rate + start_sec),
+                           wav=waveform_segment[:, start:start + seg_len],
+                           sample_rate=sample_rate)
+            # print(f'{start} {slen} {seg_len} {seg_jump} {key} {waveform_segment[:, start:start + seg_len].shape}\n')
+            yield example
+
+        # print(slen, start, seg_jump)
+        if slen - start - seg_jump > 0.12 * sample_rate:
+            key = f'{utt}-A_{sample_idx:04}-' \
+                  f'{int((start + seg_jump) / sample_rate * 100):08}-{int(slen / sample_rate * 100):08}'
+            assert start + seg_jump <= slen <= waveform_segment.shape[1],\
+                f'Start: {start + seg_jump}, end: {slen}, shape: {waveform_segment.shape[1]}'
+            example = dict(key=key,
+                           spk=((start + seg_jump) / sample_rate + start_sec, slen / sample_rate + start_sec),
+                           wav=waveform_segment[:, start + seg_jump:slen],
+                           sample_rate=sample_rate)
+            # print(f'{start} {slen} {seg_len} {seg_jump} {key}\n')
+            yield example
+
+
+def parse_feat(data):
+    """ Parse key/feat/spk from json line
+
+        Args:
+            data: Iterable[str], str is a json line has key/feat/spk
+
+        Returns:
+            Iterable[{key, feat, spk}]
+    """
+    for sample in data:
+        assert 'src' in sample
+        json_line = sample['src']
+        obj = json.loads(json_line)
+        assert 'key' in obj
+        assert 'feat' in obj
+        assert 'spk' in obj
+        key = obj['key']
+        feat_ark = obj['feat']
+        spk = obj['spk']
+        try:
+            feat = torch.from_numpy(kaldiio.load_mat(feat_ark))
+            example = dict(key=key,
+                           spk=spk,
+                           feat=feat)
+            yield example
+        except Exception as ex:
+            logging.warning('Failed to load {}'.format(feat_ark))
+
+
 def shuffle(data, shuffle_size=2500):
     """ Local shuffle the data
 
@@ -181,7 +265,7 @@ def spk_to_id(data, spk2id):
         if sample['spk'] in spk2id:
             label = spk2id[sample['spk']]
         else:
-            label = -1
+            label = sample['spk']
         sample['label'] = label
         yield sample
 
@@ -215,6 +299,15 @@ def speed_perturb(data, num_spks):
 
 
 def get_random_chunk(data, chunk_len):
+    """ Get random chunk
+
+        Args:
+            data: torch.Tensor (random len)
+            chunk_len: chunk length
+
+        Returns:
+            torch.Tensor (exactly chunk_len)
+    """
     data_len = len(data)
     data_shape = data.shape
     # random chunk
@@ -223,33 +316,49 @@ def get_random_chunk(data, chunk_len):
         data = data[chunk_start:chunk_start + chunk_len]
     else:
         # padding
-        chunk_shape = chunk_len if len(data_shape) == 1 else (chunk_len,
-                                                              data.shape[1])
-        data = np.resize(data, chunk_shape)  # resize will repeat copy
+        repeat_factor = chunk_len // data_len + 1
+        repeat_shape = repeat_factor if len(data_shape) == 1 else (repeat_factor, 1)
+        data = data.repeat(repeat_shape)
+        data = data[:chunk_len]
 
     return data
 
 
-def random_chunk(data, num_frms=200):
+def random_chunk(data, data_type='shard/raw/feat', num_frms=200):
     """ Random chunk the data into `num_frms` frames
 
         Args:
-            data: Iterable[{key, wav, label, sample_rate}]
+            data: Iterable[{key, wav/feat, label, sample_rate}]
             num_frms: num of frames for each training sample
 
         Returns:
-            Iterable[{key, wav, label, sample_rate}]
+            Iterable[{key, wav/feat, label, sample_rate}]
     """
     # Note(Binbin Zhang): We assume the sample rate is 16000,
     #                     frame shift 10ms, frame length 25ms
-    chunk_len = (num_frms - 1) * 160 + 400
+    if data_type == 'feat':
+        chunk_len = num_frms
+    else:
+        chunk_len = (num_frms - 1) * 160 + 400
+
     for sample in data:
         assert 'key' in sample
-        assert 'wav' in sample
 
-        wav = sample['wav'].numpy()[0]
-        wav = get_random_chunk(wav, chunk_len)
-        sample['wav'] = torch.from_numpy(wav).unsqueeze(0)
+        if data_type == 'feat':
+            assert 'feat' in sample
+            feat = sample['feat']
+            feat = get_random_chunk(feat, chunk_len)
+            sample['feat'] = feat
+        else:
+            assert 'wav' in sample
+            wav = sample['wav'][0]
+            try:
+                wav = get_random_chunk(wav, chunk_len)
+            except:
+                logging.warning(f'{sample["key"]} probably empty. '
+                                f'If you see this error often there might be a problem with your data.')
+                continue
+            sample['wav'] = wav.unsqueeze(0)
         yield sample
 
 
@@ -343,8 +452,27 @@ def compute_fbank(data,
                           window_type='hamming',
                           htk_compat=True,
                           use_energy=False)
-        # CMN, without CVN
-        mat = mat - torch.mean(mat, dim=0)
+        yield dict(key=sample['key'], label=sample['label'], feat=mat)
+
+
+def apply_cmvn(data, norm_mean=True, norm_var=False):
+    """ Apply CMVN
+
+        Args:
+            data: Iterable[{key, feat, label}]
+
+        Returns:
+            Iterable[{key, feat, label}]
+    """
+    for sample in data:
+        assert 'key' in sample
+        assert 'feat' in sample
+        assert 'label' in sample
+        mat = sample['feat']
+        if norm_mean:
+            mat = mat - torch.mean(mat, dim=0)
+        if norm_var:
+            mat = mat / torch.sqrt(torch.var(mat, dim=0) + 1e-8)
         yield dict(key=sample['key'], label=sample['label'], feat=mat)
 
 
diff --git a/wespeaker/utils/checkpoint.py b/wespeaker/utils/checkpoint.py
index 0879ae0..ca00c2b 100644
--- a/wespeaker/utils/checkpoint.py
+++ b/wespeaker/utils/checkpoint.py
@@ -1,6 +1,17 @@
-#!/usr/bin/env python3
-# coding=utf-8
-# Author: Hongji Wang
+# Copyright (c) 2020 Mobvoi Inc. (authors: Binbin Zhang)
+#               2021 Hongji Wang (jijijiang77@gmail.com)
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
 
 import torch
 
@@ -10,6 +21,7 @@ def load_checkpoint(model: torch.nn.Module, path: str):
         checkpoint = torch.load(path)
     else:
         checkpoint = torch.load(path, map_location='cpu')
+    print(checkpoint)
     model.load_state_dict(checkpoint, strict=False)
 
 
diff --git a/wespeaker/utils/executor.py b/wespeaker/utils/executor.py
index be175be..a727ed4 100644
--- a/wespeaker/utils/executor.py
+++ b/wespeaker/utils/executor.py
@@ -67,9 +67,11 @@ def run_epoch(dataloader,
                            width=10,
                            style='grid'))
 
+
     logger.info(
         tp.row((epoch, i + 1, scheduler.get_lr(),
                 margin_scheduler.get_margin()) +
                (loss_meter.value()[0], acc_meter.value()[0]),
                width=10,
                style='grid'))
+    return scheduler.get_lr(), margin_scheduler.get_margin(), loss_meter.value()[0], acc_meter.value()[0]
